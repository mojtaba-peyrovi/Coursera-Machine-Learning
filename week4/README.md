# Coursera Course for Machine Learning:


## Week 4: (Part 1)

We are discussing Non-linear Hypothesis and Neural Networks.

Although linear regression and logistic regression are great algorithms but they can do much when there are a lot of features and the distribution of samples is rather complicated. In these cases it is a better idea to use neural networks.

## Week 4: (Part 2)

Artificial Neural networks simulate neurons in human brain.

__Neuron:__ Neuron is a computational unit that takes inputs, does some process or computation on data and releases an output.
(Photo: neuron-in-the-brain.jpg)

Similar to human neurons we can draw ANN units that takes the input of x(i) and doest the computation (for example calculating the logistic hypothesis and returns h(x) as the neuron output.

sometimes we add x(0) also as an input which is called __Bias Unit__ which always outputs the value __one__.

When the neuron uses sigmoid function to calculate h(x) we sometimes call this function __Sigmoid Activation Function__.

Sometimes in ANN science people use the term __Weights__ instead of __parameters__ which are representing __Thetas__.
(photo: ANN-Model.jpg)

In neural networks we have a network of layers like a photo called neural-network.jpg.

The first layer is calle __Input Layer__.

The final layer is called __Output Layer__.

Any layer in the middle is called __Hiden Layer__ and any of the neurons in the layer are called __Hidden Units__.

Photo: model-representation-1.jpg
